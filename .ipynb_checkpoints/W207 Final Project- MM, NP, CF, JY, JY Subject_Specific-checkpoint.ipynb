{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interpretation of Electroencephalography Measurements for Human Movements\n",
    "\n",
    "w207 Summer 2015, Final Project\n",
    "\n",
    "By Michael Marks, Nihar Patel, Carson Forter, Ji Yan, Jeff Yau\n",
    "\n",
    "![live brain](http://s1.ibtimes.com/sites/www.ibtimes.com/files/styles/v2_article_large/public/2015/04/25/brain.jpg?itok=jIf_rHLW)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "Electroencephalography (EEG) is a non-invasive method of measuring brain activity. An array of sensors are arranged on a person's scalp. These sensors detect the electrical activity of the neurons firing immediately under the skull. Though this technology has limited spatial resolution and cannot detect electrical activity within deep brain structures, it has the advantage of having high temporal resolution; it measures electrical activity on the time scale that biological processes in the brain actually happen. This technology has many medical uses, one of which is allowing for a brain-to-computer interface. In particular, because the human brain controls movement in part with surface-oriented neurons, there is potential for using EEG to interpret muscle movements as signals from the brain. Advances in sensor hardware will allow for greater spatial resolution in the future, but the current challenge is in interpreting the raw brain signals into the intended muscle movement.\n",
    "\n",
    "On June 29th, 2015, Kaggle, a data science competition platform, introduced [a contest](https://www.kaggle.com/c/grasp-and-lift-eeg-detection) for EEG classification. The dataset was a series of EEG records from volunteers asked to repeatedly perform a task with their right hand. Each hand movement was recorded on video, and carefully documented into a matching dataset, in effect creating a set of raw sensor data matched with data of what arm movement corresponds to that data. Competitors were asked to use the sample dataset to produce the algorithm that most accurately predicts the correct arm movement from the raw data.\n",
    "\n",
    "In this workbook, we describe how our group approached the problem. We outline our preliminary research, our initial tests, how we handled the large dataset, and finally our results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries Used\n",
    "We primarily use the [scikit-learn](http://scikit-learn.org/stable/index.html) python library for this project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import time\n",
    "import random\n",
    "import gc\n",
    "import re\n",
    "import csv\n",
    "import os\n",
    "import psutil\n",
    "import sys\n",
    "\n",
    "# SK-learn libraries.\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "# scipy\n",
    "from scipy.signal import butter, lfilter\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "The data can be downloaded from Kaggle [here](https://www.kaggle.com/c/grasp-and-lift-eeg-detection/data). This workbook uses the folder structure data\\test\\ and data\\train. \n",
    "\n",
    "The EEG data has a temporal aspect to it and all data is recorded at 500 Hz, meaning that there are 500 rows of data for every second recorded. For each participant, there is a separate file for each session containing the recordings from 32 EEG sensors. Parallel to each of these files is a file describing which of 6 different arm motions are being performed at any given frame (1/500th of a second). In total there are 96 pairs of these files: 8 series for each of 12 subjects. Additionally there are two more series' worth of data for each subject without labels, which served as the test dataset for which we uploaded our predictions.  \n",
    "\n",
    "It is also worth noting that the dataset was changed by the hosts of the competition towards the end our project. See the announcement on Kaggle [here](https://www.kaggle.com/c/grasp-and-lift-eeg-detection/forums/t/15413/announcement-error-in-dataset). An error in the dataset caused there to be a time discrepancy between the labels and the associated data. This meant that we needed to retrain our model on the new dataset in order to learn weights that were actually representative of the data. Luckily, the feature engineering and dimensionality reduction that we developed on the original dataset remained applicable and we were able to successfully carry over our work to the fixed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Location of data can be changed here.\n",
    "# data_path = r'data\\train'\n",
    "data_path = r'C:\\Users\\marks\\Google Drive\\EEG Kaggle\\train'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading data\n",
    "Here we define a function for loading a subset of data into a Pandas dataframe. This is necessary because the data is too large to hold in memory on an average desktop computer, and so we will need to call this function many times on different chunks of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-Processing/Feature Engineering\n",
    "Our group spent the vast majority of our time researching the best way to pre-process the data. We attempted  feature engineering by transforming the raw data using both a priori knowledge and general data reduction techniques. We began by consulting with medical EEG researchers and reading literature on EEG processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def open_data(subjects_to_use='[1,2]',series_for_training='[1-3]'):\n",
    "    # Make a list of all the filenames with training data.\n",
    "    \n",
    "    train_data_filenames = glob.glob(data_path + r\"\\subj\" + subjects_to_use +\n",
    "                                     \"_series\"+series_for_training + \"_data.csv\")\n",
    "    # Initialize an empty dataframe.\n",
    "    train_data= pd.DataFrame()\n",
    "\n",
    "    # Load the dataframe with the contents of each file.\n",
    "    for file_ in train_data_filenames:\n",
    "        train_data = train_data.append(pd.read_csv(file_,index_col=0, header=0))\n",
    "    \n",
    "    train_data.reset_index()\n",
    "    # Make a list of all the filenames with training labels.\n",
    "    train_labels_filenames = glob.glob(data_path + r\"\\subj\" + subjects_to_use +\n",
    "                                     \"_series\"+series_for_training + \"_events.csv\")\n",
    "    print train_data.shape\n",
    "    # Initialize an empty dataframe.\n",
    "    train_labels = pd.DataFrame()\n",
    "    \n",
    "    #Load the dataframe with the contents of each file.\n",
    "    for file_ in train_labels_filenames:\n",
    "        train_labels = train_labels.append(pd.read_csv(file_,index_col=0, header=0))\n",
    "        \n",
    "    train_labels.reset_index()\n",
    "    # Return the resulting two dataframes.\n",
    "    return train_data, train_labels\n",
    "\n",
    "\n",
    "\n",
    "#Split up by subject for submission test data\n",
    "def open_test_data(subject_to_use,test_data_path):\n",
    "    # Make a list of all the filenames with training data.   \n",
    "    train_data_filenames = glob.glob(test_data_path + r\"\\subj\" + subject_to_use + \"_series*_data.csv\")\n",
    "    \n",
    "    # Initialize an empty dataframe.\n",
    "    train_data= pd.DataFrame()\n",
    "\n",
    "    # Load the dataframe with the contents of each file.\n",
    "    for file_ in train_data_filenames:\n",
    "        train_data = train_data.append(pd.read_csv(file_,index_col=0, header=0))\n",
    "    \n",
    "        \n",
    "    Subject_Strings = np.array(train_data.index)\n",
    "    train_data.reset_index()\n",
    "    # Return the resulting two dataframes.\n",
    "    return train_data,Subject_Strings\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Removing Channels**\n",
    "\n",
    "Our medical EEG consultant did not have experience with interpreting muscle movement data, but was able to share some insights into neuroanatomy. The following brain map shows the different functional regions of the brain:\n",
    "\n",
    "![brain functional regions](http://lh3.ggpht.com/_RIjx_Mg4ZVM/TNbSn_XhNcI/AAAAAAAACeY/Abc73jPpSbU/image_thumb6.png)\n",
    "\n",
    "We anticipated that the frontal lobe of the brain would contain the relevant information for our problem. As the source of muscle movements, we beleived that the region called the primary motor cortex is particularly important for predicting arm movements. The next image is a representation of what the primary motor cortex controls:\n",
    "\n",
    "![homunculus](http://brainconnection.brainhq.com/wp-content/uploads/2013/03/1b.gif)\n",
    "\n",
    "This is a coronal section of the brain (as if you were looking face-to-face with x-ray vision). The surface and about an inch under it, shaded in salmon color in the picture, is called the cortex. EEG sensors pick up the electrical firings of cells on the surface as shaded in blue, but note that the surface has grooves called gyri where the EEG sensors would have an especially hard time telling the difference between adjacently active sections of the cortex. The motor cortex, responsible for innervating our muscles, is almost always represented in the same spot and in the same order for humans, and we learned that individual differences likely wouldn't be picked up with the spatial resolution available using EEG. For example, if Sensor 1 is positioned above the motor strip at the position where the fingers are represented, we would expect that sensor to be active when the participants are closing and releasing their fingers from the object.\n",
    "\n",
    "Another important detail we learned was that the left side of the brain controls the right half of the body, so the cells we expect to be firing are on the left-side motor cortex.\n",
    "\n",
    "We produced a function to remove channels that we anticipated would contain more noise than information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Remove the channels we don't want \n",
    "def Remove_Channels(df):\n",
    "    df.drop(df.columns[[15,16,20,21,22,25,26,27,28,29,30,31,32]], axis=1, inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Frequency Filtering**\n",
    "\n",
    "We identified a paper that highlighted the oscillatory nature of neural network electrical activity. It suggested that for interpreting motor neuron activation, EEG sensor data in the 8-12 Hz and 16-24 Hz range should be used. Another recommendation was to keep all frequencies 30 Hz and under.\n",
    "\n",
    "We used the following bandpass filter function to eliminate frequencies in the raw sensor data outside of the desired ranges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def butter_bandpass(lowcut, highcut, fs, order=5):\n",
    "    nyq = 0.5 * fs\n",
    "    low = lowcut / nyq\n",
    "    high = highcut / nyq\n",
    "    b, a = butter(order, [low, high], btype='band')\n",
    "    return b, a\n",
    "\n",
    "def butter_bandpass_filter(df, lowcut, highcut, fs, order=5):\n",
    "    b, a = butter_bandpass(lowcut, highcut, fs, order=order)\n",
    "    df = pd.DataFrame(lfilter(b, a, df), columns=df.columns)\n",
    "    return df\n",
    "\n",
    "def butterworth_filter(X,k,l):\n",
    "    '''\n",
    "      Butterworth Filter:\n",
    "      scipy.signal.butter(N, Wn, btype='low', analog=False, output='ba')[source]\n",
    "        N: the order of the filter, and 5 seems to be good enough\n",
    "        Wn: critical frequency, at which point the gain drops to 1/sqrt(2) that of \n",
    "            the passband (the \"-3dB point\")\n",
    "    '''\n",
    "    b,a = butter(5,k/250.0,btype='lowpass')\n",
    "    X = lfilter(b,a,X)\n",
    "    return X\n",
    "\n",
    "\n",
    "def preprocess_data(X):\n",
    "    scaler= StandardScaler()\n",
    "    # Just standardized the X\n",
    "    X_normalized = scaler.fit_transform(X)\n",
    "    \n",
    "    # Define 2 x 20 features (based on a series of lowpass filters)\n",
    "    nFeaturesAdded=20\n",
    "    X_lowpass = np.zeros((np.shape(X_normalized)[0],nFeaturesAdded))\n",
    "    l=30\n",
    "    for i in range(nFeaturesAdded):\n",
    "        X_lowpass[:,i] = butterworth_filter(X[:,0],2-(i*0.1),l)\n",
    "        X_lowpass[:,i] = scaler.fit_transform(X_lowpass[:,i])\n",
    "    X_lowpass_squared = X_lowpass ** 2\n",
    "    X_preprocess = np.concatenate((X_lowpass, X_lowpass_squared),axis=1)\n",
    "    return X_preprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Signal Smoothing**\n",
    "\n",
    "The Kaggle dataset description explains that the labels can be off by +/- 75 ms. Also, we observed that the raw data has frequent dips and rises during both positive and negative conditions. Consequently, we decided that some method of compressing the signal temporarily and smoothing would be beneficial. This requires care because the competition rules state that future data cannot be used to predict earlier labels.\n",
    "\n",
    "We produced a number of functions designed to compress and smooth the signal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Bin the time. This was an attempt to bin the entire dataset into features based on the amount of time since test start.\n",
    "# this proved unsuccessful\n",
    "def Bin_Time(num_rows,num_bins):\n",
    "    Bin_Size = num_rows/num_bins\n",
    "    Bins = np.zeros(shape=(num_rows,num_bins))\n",
    "    Bin_Min = 0\n",
    "    Bin_Max = Bin_Size\n",
    "    for i in range(0,num_bins):\n",
    "        Bins[Bin_Min:Bin_Max,i] = 1\n",
    "        Bin_Min = Bin_Min + Bin_Size\n",
    "        Bin_Max = Bin_Max + Bin_Size\n",
    "    return Bins\n",
    "\n",
    "\n",
    "# Return a rolling metric of each column in a pandas dataframe with a given window size. Returns df of same size. \n",
    "# Metric can be mean, var, min, max, skew, or kurt.\n",
    "def df_rolling_metric(df,window, metric,multiplier='none'):\n",
    "    # eval('pd.rolling'+metric+'(df.iloc[0:,i],'+ window +',min_periods = 0).fillna(0)')\n",
    "    list_ = []\n",
    "    Num_Cols = len(df.columns)\n",
    "    if multiplier == 'abs':\n",
    "        df = df.abs()\n",
    "    if multiplier == 'square':\n",
    "        df = df**2\n",
    "    if multiplier == 'cube':\n",
    "        df = df**3   \n",
    "    for i in range(0,Num_Cols):\n",
    "        Roll_Array = eval('pd.rolling_' + str(metric)+\"(df.iloc[0:,i],\"+str(window)+\",min_periods = 0).fillna(0)\")\n",
    "        list_.append(Roll_Array)\n",
    "    new_df = pd.concat(list_,1)\n",
    "    for i in range(0,Num_Cols):\n",
    "        new_df=new_df.rename(columns = {i:metric + str(i)})\n",
    "    return np.array(new_df.astype('float32'))\n",
    "\n",
    "# Return rolling quantile of each column in a pandas dataframe with a given window and quantile. Returns df of same size. \n",
    "def df_rolling_quantile(df,window,quantile):\n",
    "    list_ = []\n",
    "    Num_Cols = len(df.columns)\n",
    "    for i in range(0,Num_Cols):\n",
    "        Roll_Array = pd.rolling_quantile(df.iloc[0:,i],window,quantile,min_periods = 0).fillna(0)\n",
    "        list_.append(Roll_Array)\n",
    "    new_df = pd.concat(list_,1)\n",
    "    return np.array(new_df.astype('float32'))\n",
    "\n",
    "\n",
    "# BE CAREFUL NOT TO SUPPLY TOO MANY COLUMNS TO THIS FUNCTION. Returns 2^N columns, where N = intitial columns. \n",
    "# Return rolling pairwise correlation of each column in a pandas dataframe with a given window. Returns df of same size. \n",
    "def df_rolling_corr(df,window):\n",
    "    list_ = []\n",
    "    Num_Cols = len(df.columns)\n",
    "    for i in range(0,Num_Cols):\n",
    "        list_.append(pd.rolling_corr(df.iloc[0:,i],window,min_periods = 0))\n",
    "    return pd.concat(list_,1)\n",
    "\n",
    "\n",
    "\n",
    "# BE CAREFUL NOT TO SUPPLY TOO MANY COLUMNS TO THIS FUNCTION. Returns 2^N columns, where N = intitial columns. \n",
    "# Return rolling pairwise correlation of each column in a pandas dataframe with a given window. Returns df of same size. \n",
    "def df_rolling_cov(df,window):\n",
    "    list_ = []\n",
    "    Num_Cols = len(df.columns)\n",
    "    for i in range(0,Num_Cols):\n",
    "        list_.append(rolling_cov(df.iloc[0:,i],window,min_periods = 0))\n",
    "    return pd.concat(list_,1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feature Reduction**\n",
    "\n",
    "We were concerned about the size of the dataset. To put it in context, series 1-8 from Subject 1 alone contains $1,422,329$ observations. With the hundreds of features we have created, to train $12$ subjects for each of the $6$ classes using more than 5 classifiers, with each having different parameters to be optimized, we (1) did not have enough time to conduct all of these training exercises on the full datasets and (2) we could not fit all rows of data in memory. This problem was exacerbated by our feature extraction methods that would produce extra columns in the data set. Therefore, we decided to try some methods of feature reduction to alleviate the memory and training-time issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#run PCA and return the number of PCs that explain the given amount of variance. \n",
    "def extract_PCs(Train_Data,Test_Data, PercentVarExplained):\n",
    "    pca = PCA()\n",
    "    pca.fit(Train_Data)  \n",
    "    \n",
    "    Explained_Variance_Ratios = pca.explained_variance_ratio_\n",
    "    for i in range(1,len(Explained_Variance_Ratios)):\n",
    "        if sum(Explained_Variance_Ratios[0:i]) >= PercentVarExplained:\n",
    "                   NumPCs = i + 1 #add 1 since numpy array ranges are not inclusive\n",
    "                   break\n",
    "    return np.float32(pca.transform(Train_Data)[:,0:NumPCs]),np.float32(pca.transform(Test_Data)[:,0:NumPCs])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Features\n",
    "After creating features and data reduction functions, we created a pipeline for testing these functions with a simple linear regression model. Through this process, we discovered that we would constantly observe around 98% accuracy; roughly 98% of labels were negative, and roughly only 2% of all labels in the dataset are positive. This is a reflection of quick motions that participants were asked to perform, and their relatively short duration compared to time at rest.\n",
    "\n",
    "We decided to judge the performance of our pre-processing steps using Area Under the Curve (AUC) scoring, which is required by the Kaggle Competition: *\"Submissions are evaluated on the mean column-wise AUC. That is, the mean of the individual areas under the ROC curve for each predicted column.\"* https://www.kaggle.com/c/grasp-and-lift-eeg-detection/details/evaluation\n",
    "\n",
    "When evaluating the predictive power of a models for binary outcomes, **accuracy**, which measures the proportion of examples classified correctly, fails to provide a good evaluation of the model performance when the distribution of the two classes are very skewed, which is case in this EEG classification problem. (See the following link, written by one of our colleagues, of the shortcoming of accuracy: http://svds.com/post/basics-classifier-evaluation-part-1)\n",
    "\n",
    "The curve, as in the AUC, is called the ** Receiver Operating Characteristic (ROC) curve **, the understanding of which requires an understanding of classification tables, which we assume. ROC provides another approach to evaluate the predictive power of a binary classifier. It represents the locus (or collection) of the ratios of $sensitivity$ to $1-specificity$, where sensitivity is the proportion of events correctly predicted and specificity is the proportion of non-events correctly predicted. Ideally, both of these proportions are high. However, there generally exists an inverse relationship between the two; cutoff points closer to zero gives higher probability that an observation will be predicted to be an event. As such, most be predicted to be events and sensitivity will be high, but so are non-events, making the specificity low. High cutoff points gives the opposite pattern. While ROC curves can be useful visual devise to compare models, it is more convenient to have a one number summary. This gives rise to  the **area** under the ROC curve, which is a measure of discrimination between events and non-events."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to the time series nature of the data, the main features we went with were rolling statistics. These served as a means of smoothing the data, and extracting relevant statistics that could provide useful features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Create a function that trains and runs a logistic regression model. Then prints and returns the AUC score\n",
    "def regression_test(metric_string, train_data, train_labels, test_data, test_labels):\n",
    "    \n",
    "    Logistic_Reg = LogisticRegression(tol = .001)    \n",
    "    Logistic_Reg.fit(train_data, train_labels)\n",
    "    prob = Logistic_Reg.predict_proba(test_data)\n",
    "    print(metric_string, \"AUC =\", round(roc_auc_score(test_labels, prob[:,1]),4))\n",
    "\n",
    "def Test_Features():\n",
    "    #just test on subject 1, series 1,2 and 3\n",
    "    train_data, train_labels = open_data('[1]','[1,2]')\n",
    "    dev_data, dev_labels = open_data('[1]','[3]')\n",
    "\n",
    "\n",
    "    train_labels=train_labels['HandStart']\n",
    "    dev_labels=dev_labels['HandStart']\n",
    "\n",
    "    print \"\\n\"\n",
    "    regression_test(\"Baseline\",train_data,train_labels,dev_data,dev_labels)\n",
    "    \n",
    "    print \"\\n\"\n",
    "    regression_test(\"lowpass filter\",preprocess_data(np.asarray(train_data)),train_labels,preprocess_data(np.asarray(dev_data)),dev_labels)\n",
    "    regression_test(\"Bandpass 2-30 Hz\",\n",
    "                    butter_bandpass_filter(train_data,2,30,500),train_labels,\n",
    "                    butter_bandpass_filter(dev_data,2,30,500),dev_labels)\n",
    "\n",
    "    print \"\\n\"\n",
    "    regression_test(\"Rolling Mean w/ Window of 100\",df_rolling_metric(train_data,100,\"mean\"),train_labels,df_rolling_metric(dev_data,100,\"mean\"),dev_labels )\n",
    "    regression_test(\"Rolling Mean w/ Window of 400\",df_rolling_metric(train_data,400,\"mean\"),train_labels,df_rolling_metric(dev_data,400,\"mean\"),dev_labels)\n",
    "    regression_test(\"Rolling Mean w/ Window of 700\",df_rolling_metric(train_data,700,\"mean\"),train_labels,df_rolling_metric(dev_data,700,\"mean\"),dev_labels)\n",
    "    regression_test(\"Rolling Mean w/ Window of 1000\",df_rolling_metric(train_data,1000,\"mean\"),train_labels,df_rolling_metric(dev_data,1000,\"mean\"),dev_labels)\n",
    "    regression_test(\"Rolling Mean w/ Window of 1500\",df_rolling_metric(train_data,1500,\"mean\"),train_labels,df_rolling_metric(dev_data,1500,\"mean\"),dev_labels)\n",
    "    regression_test(\"Rolling Mean w/ Window of 2000\",df_rolling_metric(train_data,2000,\"mean\"),train_labels,df_rolling_metric(dev_data,2000,\"mean\"),dev_labels)\n",
    "\n",
    "    print \"\\n\"\n",
    "    regression_test(\"\\nRolling Mean_Abs w/ Window of 100\",df_rolling_metric(train_data,100,\"mean\",\"abs\"),train_labels,df_rolling_metric(dev_data,100,\"mean\",\"abs\"),dev_labels)\n",
    "    regression_test(\"Rolling Mean_Abs w/ Window of 400\",df_rolling_metric(train_data,400,\"mean\",\"abs\"),train_labels,df_rolling_metric(dev_data,400,\"mean\",\"abs\"),dev_labels)\n",
    "    regression_test(\"Rolling Mean_Abs w/ Window of 700\",df_rolling_metric(train_data,700,\"mean\",\"abs\"),train_labels,df_rolling_metric(dev_data,700,\"mean\",\"abs\"),dev_labels)\n",
    "    regression_test(\"Rolling Mean_Abs w/ Window of 1000\",df_rolling_metric(train_data,1000,\"mean\",\"abs\"),train_labels,df_rolling_metric(dev_data,1000,\"mean\",\"abs\"),dev_labels)\n",
    "    regression_test(\"Rolling Mean_Abs w/ Window of 1500\",df_rolling_metric(train_data,1500,\"mean\",\"abs\"),train_labels,df_rolling_metric(dev_data,1500,\"mean\",\"abs\"),dev_labels)\n",
    "    regression_test(\"Rolling Mean_Abs w/ Window of 2000\",df_rolling_metric(train_data,2000,\"mean\",\"abs\"),train_labels,df_rolling_metric(dev_data,2000,\"mean\",\"abs\"),dev_labels)\n",
    "\n",
    "    print \"\\nTrying mean squared error to accentuate the large absolute values\"\n",
    "    regression_test(\"Rolling Mean_Square w/ Window of 100\",df_rolling_metric(train_data,100,\"mean\",\"square\"),train_labels,df_rolling_metric(dev_data,100,\"mean\",\"square\"),dev_labels)\n",
    "    regression_test(\"Rolling Mean_Square w/ Window of 400\",df_rolling_metric(train_data,400,\"mean\",\"square\"),train_labels,df_rolling_metric(dev_data,400,\"mean\",\"square\"),dev_labels)\n",
    "    regression_test(\"Rolling Mean_Square w/ Window of 700\",df_rolling_metric(train_data,700,\"mean\",\"square\"),train_labels,df_rolling_metric(dev_data,700,\"mean\",\"square\"),dev_labels)\n",
    "    regression_test(\"Rolling Mean_Square w/ Window of 1000\",df_rolling_metric(train_data,1000,\"mean\",\"square\"),train_labels,df_rolling_metric(dev_data,1000,\"mean\",\"square\"),dev_labels)\n",
    "    regression_test(\"Rolling Mean_Square w/ Window of 1500\",df_rolling_metric(train_data,1500,\"mean\",\"square\"),train_labels,df_rolling_metric(dev_data,1500,\"mean\",\"square\"),dev_labels)\n",
    "    regression_test(\"Rolling Mean_Square w/ Window of 2000\",df_rolling_metric(train_data,2000,\"mean\",\"square\"),train_labels,df_rolling_metric(dev_data,2000,\"mean\",\"square\"),dev_labels)\n",
    "\n",
    "    print \"\\n\"\n",
    "    regression_test(\"Rolling Skew w/ Window of 100\",df_rolling_metric(train_data,100,\"skew\"),train_labels,df_rolling_metric(dev_data,100,\"skew\"),dev_labels)\n",
    "    regression_test(\"Rolling Skew w/ Window of 400\",df_rolling_metric(train_data,400,\"skew\"),train_labels,df_rolling_metric(dev_data,400,\"skew\"),dev_labels)\n",
    "    regression_test(\"Rolling Skew w/ Window of 700\",df_rolling_metric(train_data,700,\"skew\"),train_labels,df_rolling_metric(dev_data,700,\"skew\"),dev_labels)\n",
    "    regression_test(\"Rolling Skew w/ Window of 1000\",df_rolling_metric(train_data,1000,\"skew\"),train_labels,df_rolling_metric(dev_data,1000,\"skew\"),dev_labels)\n",
    "    regression_test(\"Rolling Skew w/ Window of 1500\",df_rolling_metric(train_data,1500,\"skew\"),train_labels,df_rolling_metric(dev_data,1500,\"skew\"),dev_labels)\n",
    "    regression_test(\"Rolling Skew w/ Window of 2000\",df_rolling_metric(train_data,2000,\"skew\"),train_labels,df_rolling_metric(dev_data,2000,\"skew\"),dev_labels)\n",
    "\n",
    "    print \"\\n\"\n",
    "    regression_test(\"Rolling Min w/ Window of 100\",df_rolling_metric(train_data,100,\"min\"),train_labels,df_rolling_metric(dev_data,100,\"min\"),dev_labels)\n",
    "    regression_test(\"Rolling Min w/ Window of 400\",df_rolling_metric(train_data,400,\"min\"),train_labels,df_rolling_metric(dev_data,400,\"min\"),dev_labels)\n",
    "    regression_test(\"Rolling Min w/ Window of 700\",df_rolling_metric(train_data,700,\"min\"),train_labels,df_rolling_metric(dev_data,700,\"min\"),dev_labels)\n",
    "    regression_test(\"Rolling Min w/ Window of 1000\",df_rolling_metric(train_data,1000,\"min\"),train_labels,df_rolling_metric(dev_data,1000,\"min\"),dev_labels)\n",
    "    regression_test(\"Rolling Min w/ Window of 1500\",df_rolling_metric(train_data,1500,\"min\"),train_labels,df_rolling_metric(dev_data,1500,\"min\"),dev_labels)\n",
    "    regression_test(\"Rolling Min w/ Window of 2000\",df_rolling_metric(train_data,2000,\"min\"),train_labels,df_rolling_metric(dev_data,2000,\"min\"),dev_labels)\n",
    "\n",
    "    print \"\\n\"\n",
    "    regression_test(\"Rolling Max w/ Window of 100\",df_rolling_metric(train_data,100,\"max\"),train_labels,df_rolling_metric(dev_data,100,\"max\"),dev_labels)\n",
    "    regression_test(\"Rolling Max w/ Window of 200\",df_rolling_metric(train_data,200,\"max\"),train_labels,df_rolling_metric(dev_data,200,\"max\"),dev_labels)\n",
    "    regression_test(\"Rolling Max w/ Window of 400\",df_rolling_metric(train_data,400,\"max\"),train_labels,df_rolling_metric(dev_data,400,\"max\"),dev_labels)\n",
    "    regression_test(\"Rolling Max w/ Window of 700\",df_rolling_metric(train_data,700,\"max\"),train_labels,df_rolling_metric(dev_data,700,\"max\"),dev_labels)\n",
    "    regression_test(\"Rolling Max w/ Window of 1000\",df_rolling_metric(train_data,1000,\"max\"),train_labels,df_rolling_metric(dev_data,1000,\"max\"),dev_labels)\n",
    "    regression_test(\"Rolling Max w/ Window of 1500\",df_rolling_metric(train_data,1500,\"max\"),train_labels,df_rolling_metric(dev_data,1500,\"max\"),dev_labels)\n",
    "    regression_test(\"Rolling Max w/ Window of 2000\",df_rolling_metric(train_data,2000,\"max\"),train_labels,df_rolling_metric(dev_data,2000,\"max\"),dev_labels)\n",
    "\n",
    "    print \"\\n\"\n",
    "    # Trying different percentiles.\n",
    "    Main_Pct_List = [.01,.05,.10,.25,.5,.75,.9,.95,.99]\n",
    "\n",
    "    for Pct in Main_Pct_List:\n",
    "        regression_test(\"Rolling Pct \"+str(Pct*100)+ \" w/ Window of 1000\",df_rolling_quantile(train_data,400,Pct),train_labels,df_rolling_quantile(dev_data,400,Pct),dev_labels)\n",
    "\n",
    "        \n",
    "        \n",
    "# Test_Features()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Feature Selection\n",
    "Based on the performance of our tested features, certain features were selected and combined. This is by no means the best way to do feature selection, but due to limited memory and overall time, this is the method we chose. Recursive feature extraction was attempted but eventually abandoned due to processing constraints. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Create_Features(train_data,test_data):\n",
    "    Start_Time = time.time()   \n",
    "    Train_Features = np.asarray(train_data)\n",
    "    Test_Features = np.asarray(test_data)    \n",
    "    train_data = train_data.iloc[0:,0:32]\n",
    "    test_data = test_data.iloc[0:,0:32]\n",
    "    \n",
    "    Train_Features = np.concatenate((Train_Features,preprocess_data(np.asarray(train_data))),axis=1) #apply lowpass filter\n",
    "    Train_Features = np.concatenate((Train_Features,df_rolling_metric(train_data,100,\"mean\")),axis=1)\n",
    "    Train_Features = np.concatenate((Train_Features,df_rolling_metric(train_data,400,\"mean\")),axis=1)\n",
    "    Train_Features = np.concatenate((Train_Features,df_rolling_metric(train_data,1000,\"mean\")),axis=1)\n",
    "    Train_Features = np.concatenate((Train_Features,df_rolling_metric(train_data,700,\"skew\")),axis=1)\n",
    "    Train_Features = np.concatenate((Train_Features,df_rolling_metric(train_data,1350,\"skew\")),axis=1)\n",
    "    Train_Features = np.concatenate((Train_Features,df_rolling_metric(train_data,2000,\"skew\")),axis=1)\n",
    "    Train_Features = np.concatenate((Train_Features,df_rolling_metric(train_data,100,\"mean\",'square')),axis=1)\n",
    "    Train_Features = np.concatenate((Train_Features,df_rolling_metric(train_data,400,\"mean\",'square')),axis=1)\n",
    "    Train_Features = np.concatenate((Train_Features,df_rolling_metric(train_data,700,\"mean\",'square')),axis=1)\n",
    "    Train_Features = np.concatenate((Train_Features,df_rolling_metric(train_data,1000,\"mean\",'square')),axis=1)\n",
    "    Train_Features = np.concatenate((Train_Features,df_rolling_metric(train_data,100,\"min\")),axis=1)\n",
    "    Train_Features = np.concatenate((Train_Features,df_rolling_metric(train_data,700,\"min\")),axis=1)\n",
    "    Train_Features = np.concatenate((Train_Features,df_rolling_metric(train_data,1200,\"min\")),axis=1)\n",
    "    Train_Features = np.concatenate((Train_Features,df_rolling_metric(train_data,100,\"max\")),axis=1)\n",
    "    Train_Features = np.concatenate((Train_Features,df_rolling_metric(train_data,700,\"max\")),axis=1)\n",
    "    Train_Features = np.concatenate((Train_Features,df_rolling_metric(train_data,1200,\"max\")),axis=1)\n",
    "    print(\"Train Features Complete:\",round((time.time()-Start_Time),2)/60, \" Minutes Elapsed\")\n",
    "    \n",
    "    Test_Features = np.concatenate((Test_Features,preprocess_data(np.asarray(test_data))),axis=1) #apply lowpass filter\n",
    "    Test_Features = np.concatenate((Test_Features,df_rolling_metric(test_data,100,\"mean\")),axis=1)\n",
    "    Test_Features = np.concatenate((Test_Features,df_rolling_metric(test_data,400,\"mean\")),axis=1)\n",
    "    Test_Features = np.concatenate((Test_Features,df_rolling_metric(test_data,1000,\"mean\")),axis=1)\n",
    "    Test_Features = np.concatenate((Test_Features,df_rolling_metric(test_data,700,\"skew\")),axis=1)\n",
    "    Test_Features = np.concatenate((Test_Features,df_rolling_metric(test_data,1350,\"skew\")),axis=1)\n",
    "    Test_Features = np.concatenate((Test_Features,df_rolling_metric(test_data,2000,\"skew\")),axis=1)\n",
    "    Test_Features = np.concatenate((Test_Features,df_rolling_metric(test_data,100,\"mean\",'square')),axis=1)\n",
    "    Test_Features = np.concatenate((Test_Features,df_rolling_metric(test_data,400,\"mean\",'square')),axis=1)\n",
    "    Test_Features = np.concatenate((Test_Features,df_rolling_metric(test_data,700,\"mean\",'square')),axis=1)\n",
    "    Test_Features = np.concatenate((Test_Features,df_rolling_metric(test_data,1000,\"mean\",'square')),axis=1)\n",
    "    Test_Features = np.concatenate((Test_Features,df_rolling_metric(test_data,100,\"min\")),axis=1)\n",
    "    Test_Features = np.concatenate((Test_Features,df_rolling_metric(test_data,700,\"min\")),axis=1)\n",
    "    Test_Features = np.concatenate((Test_Features,df_rolling_metric(test_data,1200,\"min\")),axis=1)\n",
    "    Test_Features = np.concatenate((Test_Features,df_rolling_metric(test_data,100,\"max\")),axis=1)\n",
    "    Test_Features = np.concatenate((Test_Features,df_rolling_metric(test_data,700,\"max\")),axis=1)\n",
    "    Test_Features = np.concatenate((Test_Features,df_rolling_metric(test_data,1200,\"max\")),axis=1)\n",
    "\n",
    "    print(\"All Features Complete:\",round((time.time()-Start_Time),2)/60, \" Minutes Total\")\n",
    "    print(Test_Features.shape[1],\"total features\")\n",
    "    return Train_Features, Test_Features\n",
    "\n",
    "#this is a separate function that us used on a single data set, as opposed to both training and testing data\n",
    "def Create_Features_single_dataset(data):\n",
    "    Start_Time = time.time()   \n",
    "    Features = np.asarray(data)\n",
    "\n",
    "    print ('Creating Features........')\n",
    "    gc.collect\n",
    "    Features = np.concatenate((Features,preprocess_data(np.asarray(data))),axis=1) #apply lowpass filter\n",
    "    Features = np.concatenate((Features,df_rolling_metric(data,100,\"mean\")),axis=1)\n",
    "    Features = np.concatenate((Features,df_rolling_metric(data,400,\"mean\")),axis=1)\n",
    "    Features = np.concatenate((Features,df_rolling_metric(data,1000,\"mean\")),axis=1)\n",
    "    gc.collect\n",
    "    Features = np.concatenate((Features,df_rolling_metric(data,500,\"skew\")),axis=1)\n",
    "    Features = np.concatenate((Features,df_rolling_metric(data,1200,\"skew\")),axis=1)\n",
    "    Features = np.concatenate((Features,df_rolling_metric(data,2000,\"skew\")),axis=1)\n",
    "    gc.collect\n",
    "    Features = np.concatenate((Features,df_rolling_metric(data,200,\"mean\",'square')),axis=1)\n",
    "    Features = np.concatenate((Features,df_rolling_metric(data,500,\"mean\",'square')),axis=1)\n",
    "    Features = np.concatenate((Features,df_rolling_metric(data,1000,\"mean\",'square')),axis=1)\n",
    "    gc.collect\n",
    "    Features = np.concatenate((Features,df_rolling_metric(data,100,\"min\")),axis=1)\n",
    "    Features = np.concatenate((Features,df_rolling_metric(data,700,\"min\")),axis=1)\n",
    "    Features = np.concatenate((Features,df_rolling_metric(data,1200,\"min\")),axis=1)\n",
    "    gc.collect\n",
    "    Features = np.concatenate((Features,df_rolling_metric(data,100,\"max\")),axis=1)\n",
    "    Features = np.concatenate((Features,df_rolling_metric(data,700,\"max\")),axis=1)\n",
    "    Features = np.concatenate((Features,df_rolling_metric(data,1200,\"max\")),axis=1)\n",
    "\n",
    "    return Features\n",
    "                         "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "##Dimensionality Reduction\n",
    "Because of the large dataset, we also used principal component analysis as a means of reducing dimensionality. Using a set of principal components that explained about 90% of the variation in the data seemed to strike a good balance between a reduced number of dimensions and information loss. The function we wrote for PCA allowed us to input a desired percent variance explained. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#run PCA and return the number of PCs that explain the given amount of variance. \n",
    "def extract_PCs(Train_Features,Test_Features, PercentVarExplained):\n",
    "    Start_Time = time.time()   \n",
    "    Scale_Center = StandardScaler() #we must first scale and center the data.\n",
    "    Train_Features = np.float16(Scale_Center.fit_transform(np.array(Train_Features)))\n",
    "    gc.collect()  #Garbage collection (i.e. get rid of any outstanding unused memory)\n",
    "    Test_Features = np.float16(Scale_Center.fit_transform(np.array(Test_Features)))\n",
    "    gc.collect()\n",
    "\n",
    "    pca = PCA()\n",
    "    pca.fit(Train_Features)\n",
    "    gc.collect()\n",
    "    Explained_Variance_Ratios = pca.explained_variance_ratio_\n",
    "    for i in range(1,len(Explained_Variance_Ratios)):\n",
    "        if sum(Explained_Variance_Ratios[0:i]) >= PercentVarExplained:\n",
    "                   NumPCs = i + 1 #add 1 since numpy array ranges are not inclusive\n",
    "                   break\n",
    "    print('PCA Complete:',round((time.time()-Start_Time),2), \" seconds\")\n",
    "    print(NumPCs, 'Resultant Principal Components')\n",
    "\n",
    "    return np.float32(pca.transform(Train_Features)[:,0:NumPCs]),np.float32(pca.transform(Test_Features)[:,0:NumPCs])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##The Model\n",
    "\n",
    "In order to test a model, we defined a couple of functions that would train a model and return an AUC value for each of the six label types:\n",
    "\n",
    " - Hand Start\n",
    " - First Digit Touch\n",
    " - Both Start Load Phase\n",
    " - Lift Off\n",
    " - Replace\n",
    " - Both Released\n",
    " \n",
    "This Kaggle competition is judged on the mean of these six AUC values. Therefore, this was the metric we used to judge the performance of different models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#set parameters for Logistic Regression\n",
    "C_Value = 1\n",
    "penalty = 'l2'\n",
    "Convergence_tol = .001\n",
    "\n",
    "#Create a function that trains and runs a logistic regression model. Then prints and returns the AUC score\n",
    "def Test_AUC(train_data, train_label, test_data, test_label,Category):\n",
    "    C_Value = 1\n",
    "    penalty = 'l2'\n",
    "    Convergence_tol = .001\n",
    "    class_weight=\"auto\" \n",
    "    \n",
    "    Logistic_Reg = LogisticRegression(C = C_Value, penalty = penalty,tol=Convergence_tol,class_weight = class_weight)    \n",
    "    Logistic_Reg.fit(train_data, train_label)\n",
    "\n",
    "    prob = Logistic_Reg.predict_proba(test_data)\n",
    "    AUC = roc_auc_score(test_label, prob[:,1])\n",
    "    print(Category, \"AUC =\",round(AUC,4))\n",
    "    \n",
    "    return AUC\n",
    "\n",
    "def Test_Model(train_data,test_data,train_labels,test_labels):\n",
    "    Train_Labels_HandStart =  train_labels['HandStart'].to_sparse(fill_value=0)\n",
    "    Train_Labels_FirstDigitTouch =  train_labels['FirstDigitTouch'].to_sparse(fill_value=0)\n",
    "    Train_Labels_BothStartLoadPhase =  train_labels['BothStartLoadPhase'].to_sparse(fill_value=0)\n",
    "    Train_Labels_LiftOff =  train_labels['LiftOff'].to_sparse(fill_value=0)\n",
    "    Train_Labels_Replace =  train_labels['Replace'].to_sparse(fill_value=0)\n",
    "    Train_Labels_BothReleased =  train_labels['BothReleased'].to_sparse(fill_value=0)\n",
    "\n",
    "    Test_Labels_HandStart =  test_labels['HandStart'].to_sparse(fill_value=0)\n",
    "    Test_Labels_FirstDigitTouch =  test_labels['FirstDigitTouch'].to_sparse(fill_value=0)\n",
    "    Test_Labels_BothStartLoadPhase =  test_labels['BothStartLoadPhase'].to_sparse(fill_value=0)\n",
    "    Test_Labels_LiftOff =  test_labels['LiftOff'].to_sparse(fill_value=0)\n",
    "    Test_Labels_Replace =  test_labels['Replace'].to_sparse(fill_value=0)\n",
    "    Test_Labels_BothReleased =  test_labels['BothReleased'].to_sparse(fill_value=0)\n",
    "    \n",
    "    Start_Time = time.time()   \n",
    "    AUC_HandStart = Test_AUC(train_data,Train_Labels_HandStart.to_dense(),test_data,Test_Labels_HandStart.to_dense(), 'HandStart')\n",
    "    print(round((time.time()-Start_Time),2)/60, \" Minutes Elapsed\")\n",
    "          \n",
    "    AUC_FirstDigitTouch = Test_AUC(train_data,Train_Labels_FirstDigitTouch.to_dense(),test_data,Test_Labels_FirstDigitTouch.to_dense(), 'FirstDigitTouch')\n",
    "    print(round((time.time()-Start_Time),2)/60, \" Minutes Elapsed\")\n",
    "          \n",
    "    AUC_BothStartLoadPhase = Test_AUC(train_data,Train_Labels_BothStartLoadPhase.to_dense(),test_data,Test_Labels_BothStartLoadPhase.to_dense(), 'BothStartLoadPhase')\n",
    "    print(round((time.time()-Start_Time),2)/60, \" Minutes Elapsed\")\n",
    "          \n",
    "    AUC_LiftOff = Test_AUC(train_data,Train_Labels_LiftOff.to_dense(),test_data,Test_Labels_LiftOff.to_dense(), 'LiftOff')\n",
    "    print(round((time.time()-Start_Time),2)/60, \" Minutes Elapsed\")\n",
    "          \n",
    "    AUC_Replace = Test_AUC(train_data,Train_Labels_Replace.to_dense(),test_data,Test_Labels_Replace.to_dense(), 'Replace')\n",
    "    print(round((time.time()-Start_Time),2)/60, \" Minutes Elapsed\")\n",
    "          \n",
    "    AUC_BothReleased = Test_AUC(train_data,Train_Labels_BothReleased.to_dense(),test_data,Test_Labels_BothReleased.to_dense(), 'BothReleased')\n",
    "    print(int(time.time()-Start_Time), \" Seconds to complete\")\n",
    "          \n",
    "    print(\"Overall Logistic Regression Score = \", np.mean((AUC_HandStart, AUC_FirstDigitTouch,AUC_BothStartLoadPhase,AUC_LiftOff,AUC_Replace,AUC_BothReleased)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Testing The Model\n",
    "\n",
    "To test the model we simply looked at subject 1, series 1, 2, and 3. Series 1 and 2 (~350,000 samples) were used for training and Series 3 (~200,000 samples) was used for testing. This allowed us to test different model parameters, and features without constraining memory. We tested many different models, including:\n",
    "\n",
    " - Logistic Regression\n",
    " - Decision Trees\n",
    " - Random Forest\n",
    " - Boosted Decision Trees\n",
    " - KNN\n",
    " - Linear Discriminant Analysis\n",
    " - SVM\n",
    " - Random Forest Regressor\n",
    "\n",
    "With such a large dataset, the biggest constraint when it came to choosing a model to make our final predictions on all of the data was efficiency. Logistic regression using stochastic gradient descent proved to be one of the most computationally efficient methods we could find. Further, the strong assumptions and relatively low variance of logistic regression were actually a huge advantage when working with the EEG data. This is largely because the EEG data is inherently noisy: the sensors used to collect the data can be affected by everything from their position on the subject's head to the way that that particular person's brain works. All of those variations mean that there is lots of variance in the training data and thus a real danger of overfitting and hurting our model when we go to apply it to the test set. As a low-variance model, logistic regression seemed to be a good choice to prevent overfitting. \n",
    "\n",
    "Our testing validated these ideas: logistic regression resulted in the highest AUC during testing (~.93). As a final note, it is possible that neural network may have been a viable option; however, due to time constraints and issues with Theano on windows, neural networks were not attempted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Start_Time = time.time()   \n",
    "\n",
    "# #Open the data\n",
    "# train_data, train_labels = open_data('[1]','[1,2]')\n",
    "# test_data, test_labels = open_data('[1]','[3]')\n",
    "\n",
    "\n",
    "# #transform into features    \n",
    "# train_data, test_data = Create_Features(train_data,test_data)    \n",
    "\n",
    "\n",
    "# #perform dimensionality reduction. We'll use the PCs that explain 90% of the variance.\n",
    "# train_data, test_data = extract_PCs(train_data, test_data ,.93)\n",
    "# Test_Model(train_data,test_data,train_labels,test_labels)\n",
    "\n",
    "# print(round((time.time()-Start_Time),2)/60, \"Total Minutes to Complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    " \n",
    " \n",
    " \n",
    " \n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Creating a Submission\n",
    "\n",
    "Now that we had chosen a model (logistic regression) that we were confident would be a good predictor and be efficient at scale, it was now time to create a submission to the Kaggle competition. Our initial attempts to scale the logistic regression model ran into memory issues, so we attempted two different methods of prediction: batch training and fitting our logistic regression model one subject at a time and utilizing a different model that had a .partial_fit() method for \"out of core\" (out of memory) learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Dealing with Memory Limitations\n",
    "Due to the size of the training dataset, we were continually running into memory limitations. In order to test how different methods affected memory usage, we created a function to return the current memory used by the python script. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def memory(Print_String):\n",
    "    process = psutil.Process(os.getpid())\n",
    "    print process.get_memory_info()[0] / float(2 ** 20), \"MB in use \"+Print_String   # return the memory usage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch Training our Logistic Regression Model\n",
    "\n",
    "This is the helper method that generates an output csv file that contains the predicted probability of each event happening for each row of test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "outputFileName = 'submission.csv'\n",
    "predictedProb = []\n",
    "def SaveProb(train_data, train_label, test_data):    \n",
    "    Logistic_Reg = LogisticRegression(C = C_Value, penalty = penalty,tol=Convergence_tol,class_weight=class_weight)    \n",
    "    Logistic_Reg.fit(train_data, train_label)\n",
    "    prob = Logistic_Reg.predict_proba(test_data)\n",
    "    predictedProb.append([Logistic_Reg.predict_proba(test_feature)[0][1] for test_feature in test_data])\n",
    "\n",
    "def GenerateOutput():\n",
    "    GenerateOutput(PCs_Train,Train_Labels_HandStart.to_dense(),PCs_Test)\n",
    "    GenerateOutput(PCs_Train,Train_Labels_FirstDigitTouch.to_dense(),PCs_Test)\n",
    "    GenerateOutput(PCs_Train,Train_Labels_BothStartLoadPhase.to_dense(),PCs_Test)\n",
    "    GenerateOutput(PCs_Train,Train_Labels_LiftOff.to_dense(),PCs_Test)\n",
    "    GenerateOutput(PCs_Train,Train_Labels_Replace.to_dense(),PCs_Test)\n",
    "    GenerateOutput(PCs_Train,Train_Labels_BothReleased.to_dense(),PCs_Test)\n",
    "\n",
    "    ids = np.array(test_data[test_data.columns[0]].values.astype(str))\n",
    "    cols = ['HandStart','FirstDigitTouch','BothStartLoadPhase','LiftOff','Replace','BothReleased']\n",
    "    submission = pd.DataFrame(index=ids, columns=cols, data=np.array(predictedProb).T)\n",
    "    submission.to_csv(outputFileName,index_label='id',float_format='%.3f') \n",
    "    \n",
    "Start_Time = time.time()\n",
    "#GenerateOutput()  # it is an expensive operation to generate submission output for all subjects on all series\n",
    "print \"Generate submission output:\", int(time.time()-Start_Time), \" Seconds\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could not run model training utilizing the whole dataset for all subjects on one machine due to memory constraint. To get around it, instead, we run one model prediction for each subject separately and later combines the individual predicted output into one final submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Helper Shell Scripts\n",
    "\n",
    "# This generates each output csv for each subject\n",
    "python msubmit.py 1 1.csv\n",
    "python msubmit.py 2 2.csv\n",
    "python msubmit.py 3 3.csv\n",
    "python msubmit.py 4 4.csv\n",
    "python msubmit.py 5 5.csv\n",
    "python msubmit.py 6 6.csv\n",
    "python msubmit.py 7 7.csv\n",
    "python msubmit.py 8 8.csv\n",
    "python msubmit.py 9 9.csv\n",
    "python msubmit.py 10 10.csv\n",
    "python msubmit.py 11 11.csv\n",
    "python msubmit.py 12 12.csv\n",
    "\n",
    "# This combines each subject output into one final submission csv\n",
    "cat 1.csv > final.csv\n",
    "tail -n +2 2.csv >> final.csv\n",
    "tail -n +2 3.csv >> final.csv\n",
    "tail -n +2 4.csv >> final.csv\n",
    "tail -n +2 5.csv >> final.csv\n",
    "tail -n +2 6.csv >> final.csv\n",
    "tail -n +2 7.csv >> final.csv\n",
    "tail -n +2 8.csv >> final.csv\n",
    "tail -n +2 9.csv >> final.csv\n",
    "tail -n +2 10.csv >> final.csv\n",
    "tail -n +2 11.csv >> final.csv\n",
    "tail -n +2 12.csv >> final.csv\n",
    "\n",
    "# Finally, we use a threshold to turn highest predicted probablity of each class into a positive case for final prediction\n",
    "\n",
    "import pandas as pd\n",
    " \n",
    "threshold = 0.2\n",
    "val = 1\n",
    "df = pd.read_csv('final.csv',index_col=None, header=0)\n",
    " \n",
    "df.HandStart[df.HandStart > threshold] = val\n",
    "df.FirstDigitTouch[df.FirstDigitTouch > threshold] = val\n",
    "df.BothStartLoadPhase[df.BothStartLoadPhase > threshold] = val\n",
    "df.LiftOff[df.LiftOff > threshold] = val\n",
    "df.Replace[df.Replace > threshold] = val\n",
    "df.BothReleased[df.BothReleased > threshold] = val\n",
    " \n",
    "df.to_csv('normalized.csv',index_label='id',float_format='%.3f') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch Training All The Data With .partial_fit()\n",
    "\n",
    "Through the feature selection processes we tried different methods to conserve memory, but no solution saved space  on the order of magnitude necessary to fit on a standard desktop computer (16 Gb RAM). We decided to use a model that permits training on batches of data sequentially. The options available in Scikit-Learn include:\n",
    "\n",
    "- Multinomial Naive Bayes\n",
    "- Bernoulli Naive Bayes\n",
    "- Perceptron\n",
    "- SGD Classifier\n",
    "- Passive Aggressive Classifier\n",
    "- SGD Regressor\n",
    "\n",
    "These functions all contain a .partial_fit() method for \"out of core\" (out of memory) learning.\n",
    "\n",
    "After a quickly testing all of the different models with their default settings, we chose an SGD classifier due to a higher AUC and quicker training time. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Stochastic Gradient Descent\n",
    "<font color='red', size =3>Need to add details on Stochastic Gradient Descent here</font>\n",
    " - **Batch_Train_SGD** - This function takes a subject and the batches of series as input. It then trains a classifier for each of the six labels in batches. It returns these trained models and the PCA transformations (i.e. the eigenvectors and eigenvalues)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def Batch_Train_SGD(subject,series,PercentVarExplained):\n",
    "    Overall_Start_Time = time.time()\n",
    "    counter = 1\n",
    "    SGD_HandStart = SGDClassifier(loss = 'log',n_jobs = 7,class_weight=\"auto\",penalty  = 'l2',alpha = .001)    \n",
    "    SGD_FirstDigitTouch = SGDClassifier(loss = 'log',n_jobs = 7,class_weight=\"auto\",penalty  = 'l2',alpha = .001)    \n",
    "    SGD_BothStartLoadPhase = SGDClassifier(loss = 'log',n_jobs = 7,class_weight=\"auto\",penalty  = 'l2',alpha = .001)    \n",
    "    SGD_LiftOff = SGDClassifier(loss = 'log',n_jobs = 7,class_weight=\"auto\",penalty  = 'l2',alpha = .001)    \n",
    "    SGD_Replace = SGDClassifier(loss = 'log',n_jobs = 7,class_weight=\"auto\",penalty  = 'l2',alpha = .001)    \n",
    "    SGD_BothReleased = SGDClassifier(loss = 'log',n_jobs = 7,class_weight=\"auto\",penalty  = 'l2',alpha = .001)    \n",
    "\n",
    "    for series in series_batches:\n",
    "        train_data, train_labels = open_data(subject,series)\n",
    "        train_labels = train_labels.to_sparse(fill_value=0)\n",
    "        #transform into features    \n",
    "        train_data = Create_Features_single_dataset(train_data) \n",
    "        print \"features completed\"\n",
    "        \n",
    "        #We fit the PCA to the first batch and then apply it to all subsequent batches and test data. \n",
    "        if counter ==1:\n",
    "            PCA_Start = time.time()\n",
    "            Scale_Center = StandardScaler() #we must first scale and center the data.\n",
    "            train_data = np.float16(Scale_Center.fit_transform(np.array(train_data)))\n",
    "            print train_data.shape\n",
    "            gc.collect()  #Garbage collection (i.e. get rid of any outstanding unused memory)\n",
    "            pca = PCA()\n",
    "            pca.fit(train_data)\n",
    "            gc.collect() \n",
    "            Explained_Variance_Ratios = pca.explained_variance_ratio_\n",
    "            for i in range(1,len(Explained_Variance_Ratios)):\n",
    "                if sum(Explained_Variance_Ratios[0:i]) >= PercentVarExplained:\n",
    "                    NumPCs = i + 1 #add 1 since numpy array ranges are not inclusive\n",
    "                    break\n",
    "            del Explained_Variance_Ratios\n",
    "            print(\"PCA Complete:\", NumPCs, \"Resultant Principal Components:\" ,round((time.time()-Overall_Start_Time),2)/60, \"Minutes\")\n",
    "        counter = counter + 1\n",
    "\n",
    "        train_data = np.float32(pca.transform(train_data)[:,0:NumPCs])\n",
    "        gc.collect()\n",
    "        train_data = np.float16(Scale_Center.fit_transform(np.array(train_data)))\n",
    "        gc.collect() \n",
    "        SGD_HandStart.partial_fit(train_data, train_labels['HandStart'].to_dense(),classes = [0,1])\n",
    "        SGD_FirstDigitTouch.partial_fit(train_data, train_labels['FirstDigitTouch'].to_dense(),classes = [0,1])     \n",
    "        SGD_BothStartLoadPhase.partial_fit(train_data, train_labels['BothStartLoadPhase'].to_dense(),classes = [0,1])\n",
    "        SGD_LiftOff.partial_fit(train_data, train_labels['LiftOff'].to_dense(),classes = [0,1])\n",
    "        SGD_Replace.partial_fit(train_data, train_labels['Replace'].to_dense(),classes = [0,1])\n",
    "        SGD_BothReleased.partial_fit(train_data, train_labels['BothReleased'].to_dense(),classes = [0,1])\n",
    "        gc.collect()     \n",
    "    print(\"Subject\", subject,\"Model Fit Complete:\", round((time.time()-Overall_Start_Time),2)/60, \"Total Minutes\")\n",
    "    \n",
    "    return pca, NumPCs,SGD_HandStart,SGD_FirstDigitTouch,SGD_BothStartLoadPhase,SGD_LiftOff,SGD_Replace,SGD_BothReleased\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Functions for Creating a Submission File\n",
    "\n",
    " - **Create_Submission_Data** - This function takes a subject ID and the output from Batch_Train_SGD as input (The trained models). It then loads the test data for that subject and saves the predictions for each of the six labels as a csv files so it does not need to be stored in memory.  \n",
    " - **Run_Full_Submission_Model** - combines the functionality of the Batch_Train_SGD and Create_Submission_Data functions into one single function. \n",
    " - **Combine_Output_Files** - combines all of the csv files output by Create_Submission_Data into one file.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def Create_Submission_Data(Subj_ID,PercentVarExplained,test_data_path,pca,NumPCs,SGD_HandStart,SGD_FirstDigitTouch,SGD_BothStartLoadPhase,SGD_LiftOff,SGD_Replace,SGD_BothReleased):\n",
    "    print Subj_ID\n",
    "    train_data, Subject_ID_Strings = open_test_data(str(Subj_ID),test_data_path)\n",
    "    print train_data.shape\n",
    "    \n",
    "    #transform into features  \n",
    "    gc.collect() \n",
    "    train_data = Create_Features_single_dataset(train_data) \n",
    "    gc.collect()       \n",
    "    print train_data.shape\n",
    "    Scale_Center = StandardScaler() #we must first scale and center the data.\n",
    "    train_data = np.float16(Scale_Center.fit_transform(np.array(train_data)))\n",
    "    gc.collect()  #Garbage collection (i.e. get rid of any outstanding unused memory)\n",
    "    print train_data.shape\n",
    "    train_data = np.float32(pca.transform(train_data)[:,0:NumPCs])\n",
    "    \n",
    "    train_data = np.float16(Scale_Center.fit_transform(np.array(train_data)))\n",
    "    \n",
    "    HandStart_Proba = np.float16(SGD_HandStart.predict_proba(train_data)[:,1])\n",
    "    FirstDigitTouch_Proba = np.float16(SGD_FirstDigitTouch.predict_proba(train_data)[:,1])\n",
    "    BothStartLoadPhase_Proba = np.float16(SGD_BothStartLoadPhase.predict_proba(train_data)[:,1])\n",
    "    LiftOff_Proba = np.float16(SGD_LiftOff.predict_proba(train_data)[:,1])  \n",
    "    Replace_Proba = np.float16(SGD_Replace.predict_proba(train_data)[:,1])\n",
    "    BothReleased_Proba = np.float16(SGD_BothReleased.predict_proba(train_data)[:,1])\n",
    "    \n",
    "    del train_data  \n",
    "    \n",
    "    Subj_Probabilities = np.transpose(np.vstack([Subject_ID_Strings,HandStart_Proba,FirstDigitTouch_Proba,BothStartLoadPhase_Proba,LiftOff_Proba,Replace_Proba,BothReleased_Proba]))\n",
    "    \n",
    "    File_Str = Output_Path + \"\\Subject\" + str(Subj_ID) + \"Probs.csv\"  \n",
    "    np.savetxt(File_Str, Subj_Probabilities, delimiter=\",\",fmt=\"%s\",comments='')\n",
    "\n",
    "    \n",
    "def Combine_Output_Files(Output_Path):\n",
    "    output_filenames = glob.glob(Output_Path + \"\\*Probs.csv\"  )\n",
    "    print output_filenames\n",
    "    # Initialize an empty dataframe.\n",
    "    All_Probabilities= pd.DataFrame()\n",
    "\n",
    "    # Load the dataframe with the contents of each file.\n",
    "    for file_ in output_filenames:\n",
    "        All_Probabilities = All_Probabilities.append(pd.read_csv(file_))\n",
    "    \n",
    "    File_Str = \"SubmissionFile.csv\"  \n",
    "    np.savetxt(File_Str, All_Probabilities, delimiter=\",\", header = \"id,HandStart,FirstDigitTouch,BothStartLoadPhase,LiftOff,Replace,BothReleased\",fmt=\"%s\",comments='')\n",
    "\n",
    "    \n",
    "def Run_Full_Submission_Model(subjects,series_batches,PercentVarExplained,test_data_path,Output_Path):\n",
    "    Overall_Start_Time = time.time()\n",
    "    counter = 1\n",
    "    for i in range(0,len(subjects)):\n",
    "        Subj_ID = subjects[i]\n",
    "        print \"Subject\" + str(Subj_ID) +\" ....\"\n",
    "        Start_Time = time.time()\n",
    "        pca, NumPCs, SGD_HandStart,SGD_FirstDigitTouch,SGD_BothStartLoadPhase,SGD_LiftOff,SGD_Replace,SGD_BothReleased = Batch_Train_SGD(str(Subj_ID),series_batches,PercentVarExplained)\n",
    "        \n",
    "        Current_Loop_Submission_Data = Create_Submission_Data(str(Subj_ID),PercentVarExplained,test_data_path,pca,NumPCs,SGD_HandStart,SGD_FirstDigitTouch,SGD_BothStartLoadPhase,SGD_LiftOff,SGD_Replace,SGD_BothReleased)\n",
    "        gc.collect()\n",
    "\n",
    "        print \"Subject \"+str(Subj_ID)+\" Prediction Complete: \" + str(round((time.time()-Start_Time),2)/60)+ \" Total Minutes\" \n",
    "    \n",
    "    Combine_Output_Files(Output_Path)\n",
    "    print round((time.time()-Overall_Start_Time),2)/60, \"Total Minutes\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Create Submission File\n",
    "\n",
    "This section of code calls all the previously defined functions to create a .csv which can be submitted for the Kaggle competition. \n",
    " - **test_data_path** - the path containing the 24 files of test data. There should be two files for each subject (series 9 and 10)\n",
    " - **Output_Path** - the path to which the individual subject prediction probabilities csv files will be written. \n",
    " - **subjects** - the subjects upon which to train the model. The way this SGD model is set up, a model will be trained for each subject in this list. Each subjects test data will be predicted with their own model. This is much like was done with the batch logistic regression; however, the SGD allows the models to be trained in batches. Therefore, each subject's model is trained in four separate batches. This batch training allows a submission file to be generated with only 16 GB of RAM. \n",
    " - **series_batches** - this is a list of the batches of series upon which the models will be trained. Each item in the list is a regex string for a range of series numbers. \n",
    " - **PercentVarExplained** - This model uses PCA as a means of dimensionality reduction. This variable sets the desired amount of variance explained by returned principal components. For example, if this variable is set to 0.9, the principal components that explain 90% of the variation in the data will be used as features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject10 ....\n",
      "(479260, 32)\n",
      "Creating Features........\n",
      "features completed\n",
      "(479260L, 552L)\n",
      "('PCA Complete:', 67, 'Resultant Principal Components:', 2.440833333333333, 'Minutes')\n",
      "(354201, 32)\n",
      "Creating Features........\n",
      "features completed\n",
      "(393902, 32)\n",
      "Creating Features........\n",
      "features completed\n",
      "(259552, 32)\n",
      "Creating Features........\n",
      "features completed\n",
      "('Subject', '10', 'Model Fit Complete:', 6.629833333333334, 'Total Minutes')\n",
      "10\n",
      "(257237, 32)\n",
      "Creating Features........\n",
      "(257237L, 552L)\n",
      "(257237L, 552L)\n",
      "Subject 10 Prediction Complete: 7.75216666667 Total Minutes\n",
      "Subject11 ....\n",
      "(371097, 32)\n",
      "Creating Features........\n",
      "features completed\n",
      "(371097L, 552L)\n",
      "('PCA Complete:', 76, 'Resultant Principal Components:', 1.9508333333333332, 'Minutes')\n",
      "(407697, 32)\n",
      "Creating Features........\n",
      "features completed\n",
      "(466771, 32)\n",
      "Creating Features........\n",
      "features completed\n",
      "(275472, 32)\n",
      "Creating Features........\n",
      "features completed\n",
      "('Subject', '11', 'Model Fit Complete:', 6.833166666666667, 'Total Minutes')\n",
      "11\n",
      "(277497, 32)\n",
      "Creating Features........\n",
      "(277497L, 552L)\n",
      "(277497L, 552L)\n",
      "Subject 11 Prediction Complete: 8.28216666667 Total Minutes\n",
      "Subject12 ....\n",
      "(421170, 32)\n",
      "Creating Features........\n",
      "features completed\n",
      "(421170L, 552L)\n",
      "('PCA Complete:', 82, 'Resultant Principal Components:', 2.678833333333333, 'Minutes')\n",
      "(387101, 32)\n",
      "Creating Features........\n",
      "features completed\n",
      "(497139, 32)\n",
      "Creating Features........"
     ]
    }
   ],
   "source": [
    "test_data_path = r'C:\\Users\\marks\\Google Drive\\EEG Kaggle\\test'\n",
    "Output_Path = r'C:\\Users\\marks\\Documents\\GitHub\\w207_EEG\\Output'\n",
    "subjects = [10,11,12] #subjects for training. each one will be done on it's own, batch training a model based on the batches below. \n",
    "series_batches = ['[1-2]','[3-4]','[5-6]','[7-8]'] #series for training. needs to be in batches\n",
    "PercentVarExplained = .9\n",
    "\n",
    "Run_Full_Submission_Model(subjects,series_batches,PercentVarExplained,test_data_path,Output_Path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
